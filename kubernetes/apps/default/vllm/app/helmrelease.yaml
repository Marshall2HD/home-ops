---
# yaml-language-server: $schema=https://kubernetes-schemas.pages.dev/helm.toolkit.fluxcd.io/helmrelease_v2.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: vllm
spec:
  interval: 30m
  timeout: 30m
  chart:
    spec:
      chart: vllm-stack
      version: 0.1.10
      sourceRef:
        kind: HelmRepository
        name: vllm
      interval: 30m
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      strategy: rollback
      retries: 3

  valuesFrom:
    - kind: Secret
      name: vllm-secret
      valuesKey: HF_TOKEN
      targetPath: servingEngineSpec.modelSpec[0].hf_token

  values:
    routerSpec:
      enabled: true
      replicaCount: 1
      route:
        main:
          enabled: true
          apiVersion: gateway.networking.k8s.io/v1
          kind: HTTPRoute
          hostnames:
            - vllm.hades.casa
          parentRefs:
            - name: envoy-internal
              namespace: network

    servingEngineSpec:
      runtimeClassName: nvidia

      modelSpec:
        - name: qwen-7b
          repository: vllm/vllm-openai
          tag: v0.8.0
          modelURL: Qwen/Qwen2.5-7B-Instruct
          replicaCount: 1

          requestCPU: 4
          requestMemory: 2Gi
          limitMemory: 24Gi
          requestGPU: 1

          pvcStorage: 50Gi
          pvcAccessMode:
            - ReadWriteOnce

          vllmConfig:
            enableChunkedPrefill: true
            enablePrefixCaching: true
            maxModelLen: 4096
            dtype: float16
            extraArgs:
              - "--disable-log-requests"
              - "--gpu-memory-utilization"
              - "0.90"
              - "--max-num-seqs"
              - "32"

          shmSize: 8Gi

          env:
            - name: TZ
              value: America/New_York
            - name: HF_HOME
              value: "/data"
            - name: NVIDIA_DRIVER_CAPABILITIES
              value: all
            - name: NVIDIA_VISIBLE_DEVICES
              value: all

          nodeSelector:
            nvidia.feature.node.kubernetes.io/gpu: "true"

          tolerations:
            - key: nvidia.com/gpu
              operator: Exists
              effect: NoSchedule

    observabilitySpec:
      enabled: true
      serviceMonitor:
        enabled: true
